{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Question 5\n",
        "Create a Model for Sentiment Analysis using RNN (Applying Embedding\n",
        "Technique)"
      ],
      "metadata": {
        "id": "B-ckQD36MpaU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "uF_ECu-vMfrJ"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load and Preprocess the dataset\n",
        "max_features = 10000  # Number of words to consider as features\n",
        "maxlen = 500  # Cut texts after this number of words (among the top max_features)"
      ],
      "metadata": {
        "id": "Vctse_UeMtqf"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the IMDb dataset\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)"
      ],
      "metadata": {
        "id": "j27kjMt5MtR2"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad sequences (to ensure equal length for all input sequences)\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)"
      ],
      "metadata": {
        "id": "UUxJIoxVM3hf"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Define the RNN model\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 32, input_length=maxlen))  # Embedding layer\n",
        "model.add(SimpleRNN(32))  # RNN layer with 32 units\n",
        "model.add(Dense(1, activation='sigmoid'))  # Output layer (for binary classification)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eO_XV56pM47T",
        "outputId": "854d8950-3c29-4e6d-9921-f057168502d5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "65pcgnJ2M9KY"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Train the model\n",
        "batch_size = 32\n",
        "epochs = 10"
      ],
      "metadata": {
        "id": "qnP8xSdrNAlH"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GImVYFRLNCkh",
        "outputId": "c76c4e52-fe61-4f08-80ad-f5a8e71ed1b6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 114ms/step - accuracy: 0.5788 - loss: 0.6654 - val_accuracy: 0.6952 - val_loss: 0.5817\n",
            "Epoch 2/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 112ms/step - accuracy: 0.7737 - loss: 0.4930 - val_accuracy: 0.8004 - val_loss: 0.4628\n",
            "Epoch 3/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 132ms/step - accuracy: 0.8733 - loss: 0.3107 - val_accuracy: 0.8012 - val_loss: 0.4606\n",
            "Epoch 4/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 133ms/step - accuracy: 0.9428 - loss: 0.1653 - val_accuracy: 0.8084 - val_loss: 0.5272\n",
            "Epoch 5/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 115ms/step - accuracy: 0.9791 - loss: 0.0694 - val_accuracy: 0.7608 - val_loss: 0.7312\n",
            "Epoch 6/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 116ms/step - accuracy: 0.9863 - loss: 0.0500 - val_accuracy: 0.6366 - val_loss: 0.6491\n",
            "Epoch 7/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 118ms/step - accuracy: 0.7400 - loss: 0.5101 - val_accuracy: 0.7036 - val_loss: 0.5856\n",
            "Epoch 8/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 116ms/step - accuracy: 0.8508 - loss: 0.3423 - val_accuracy: 0.7764 - val_loss: 0.5239\n",
            "Epoch 9/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 122ms/step - accuracy: 0.9121 - loss: 0.2329 - val_accuracy: 0.7116 - val_loss: 0.6057\n",
            "Epoch 10/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 115ms/step - accuracy: 0.9089 - loss: 0.2325 - val_accuracy: 0.7152 - val_loss: 0.6633\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {test_acc:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwVwtB75NHlN",
        "outputId": "61ebef9f-cd0c-4b66-df1a-f92c52e3302a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 28ms/step - accuracy: 0.7183 - loss: 0.6487\n",
            "Test Accuracy: 0.72\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Save the model (optional)\n",
        "model.save('sentiment_analysis_rnn_model.h5')\n",
        "print(\"Model saved successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nyuk1KcqSYbz",
        "outputId": "22e8db92-49b5-4596-b743-7e0937f00e63"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 3**\n",
        "This dataset is a collection of images from the internet, played really amazing\n",
        "player (So, can hope for perfection in shots). Then the data was augmented to give\n",
        "rise to the data I provide in front of you.\n",
        "https://www.kaggle.com/datasets/aneesh10/cricket-shot-dataset\n",
        "General Information:\n",
        "The directory drives consist of the cover drive, straight drive and off drive.\n",
        "The directory legglance-flick contains the images for the leg glance and flick shot.\n",
        "The directory pullshot has the images for pull shot.\n",
        "The directory sweep has the image for sweep shot.\n",
        "This dataset can be used for various purposes. It can be used for:\n",
        "Apply any pre-trained model for classification of shot.\n",
        "Note: This dataset is already augmented and some images may be pretty bad. I\n",
        "would suggest to not augment it further"
      ],
      "metadata": {
        "id": "dXpdlgCoO7pf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsSQ22UtQS0s",
        "outputId": "a1a6766d-c0d6-40a3-ab74-9d1a3c4d3023"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "OXyIsGMSOUfL"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d aneesh10/cricket-shot-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_0GQkkWO1V_",
        "outputId": "d116196e-6147-4811-e46b-4f86676d04fc"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/aneesh10/cricket-shot-dataset\n",
            "License(s): unknown\n",
            "cricket-shot-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the dataset\n",
        "with zipfile.ZipFile(\"cricket-shot-dataset.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"cricket_shot_dataset\")"
      ],
      "metadata": {
        "id": "kPLrTd8LPChX"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up paths based on your dataset structure\n",
        "data_dir = '/content/cricket_shot_dataset/data'"
      ],
      "metadata": {
        "id": "4beKwrF7PGto"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preprocessing\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2  # Use 80% of data for training, 20% for validation\n",
        ")"
      ],
      "metadata": {
        "id": "5aYb40I1PIwX"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoSYVsynPLvf",
        "outputId": "ff5c80d9-0881-4cd8-8d57-6540985c1c13"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3779 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBkvN9pIPOcj",
        "outputId": "f7da8f8e-2a16-4649-df26-7795406e2df5"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 944 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the ResNet50 model pre-trained on ImageNet\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ],
      "metadata": {
        "id": "lxKtPVx-PQm-"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze the base model layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "eWGWLEr7PTO-"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add custom layers for fine-tuning\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(train_generator.num_classes, activation='softmax')(x)"
      ],
      "metadata": {
        "id": "Cs4bUdLwPVUq"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ],
      "metadata": {
        "id": "V-1J7tqYPXUg"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model with the correct argument\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "6Hx_Al_zPZRt"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
        "    epochs=2\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLjDVwUWPcR7",
        "outputId": "1903e053-79b8-4d84-9292-e621e726a8b8"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m813s\u001b[0m 7s/step - accuracy: 0.4079 - loss: 1.2918 - val_accuracy: 0.3901 - val_loss: 1.3231\n",
            "Epoch 2/2\n",
            "\u001b[1m  1/118\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:33\u001b[0m 6s/step - accuracy: 0.3750 - loss: 1.2888"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.3750 - loss: 1.2888 - val_accuracy: 0.4375 - val_loss: 1.3203\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the validation set\n",
        "validation_generator.reset()  # Reset the validation generator\n",
        "preds = model.predict(validation_generator, steps=validation_generator.samples // validation_generator.batch_size + 1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-qlqnjDPeQ3",
        "outputId": "1c3a39d4-d495-4a01-d4e7-a2779b92cf75"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 6s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get true labels\n",
        "y_true = validation_generator.classes\n"
      ],
      "metadata": {
        "id": "Yf6CaUzHPgDW"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert predicted probabilities to class labels\n",
        "y_pred = preds.argmax(axis=1)"
      ],
      "metadata": {
        "id": "NOyc_wjsUPqH"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate classification report\n",
        "print(classification_report(y_true, y_pred, target_names=validation_generator.class_indices.keys()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrc6rMwpUR23",
        "outputId": "c762757d-e087-49ff-9fff-7e4616bb4e29"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "          drive       0.26      0.38      0.31       244\n",
            "legglance-flick       0.27      0.12      0.16       224\n",
            "       pullshot       0.26      0.24      0.25       252\n",
            "          sweep       0.24      0.28      0.26       224\n",
            "\n",
            "       accuracy                           0.26       944\n",
            "      macro avg       0.26      0.25      0.25       944\n",
            "   weighted avg       0.26      0.26      0.25       944\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Do_g_otLdtih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4dKVyLJmdtcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hjdKm4pxdtY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4 B\n",
        ".Draw a given model using keras Functional API    "
      ],
      "metadata": {
        "id": "270PoHDqduiF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Dense, Concatenate\n",
        "from keras.models import Model\n",
        "\n",
        "# Input layers\n",
        "input_1 = Input(shape=(32,))\n",
        "input_2 = Input(shape=(128,))\n",
        "\n",
        "# Branch 1\n",
        "dense_1 = Dense(8, activation='relu')(input_1)\n",
        "dense_2 = Dense(4, activation='relu')(dense_1)\n",
        "\n",
        "# Branch 2\n",
        "dense_3 = Dense(64, activation='relu')(input_2)\n",
        "dense_4 = Dense(32, activation='relu')(dense_3)\n",
        "dense_5 = Dense(4, activation='relu')(dense_4)\n",
        "\n",
        "# Concatenate\n",
        "concatenated = Concatenate()([dense_2, dense_5])\n",
        "\n",
        "# Final layers\n",
        "dense_6 = Dense(2, activation='relu')(concatenated)\n",
        "dense_7 = Dense(1, activation='sigmoid')(dense_6)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=[input_1, input_2], outputs=dense_7)"
      ],
      "metadata": {
        "id": "Tx-6BtJIdtOv"
      },
      "execution_count": 53,
      "outputs": []
    }
  ]
}